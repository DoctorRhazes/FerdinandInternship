{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file c:\\python3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# erstes webscraping beispiel: einlesen des html codes einer website als string\n",
    "# ausgabe mit BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WebsiteString = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "soup = BeautifulSoup(WebsiteString.read(),\"html\")\n",
    "print(soup) # auch möglich: print(WebsiteString.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WebsiteString = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "soup = BeautifulSoup(WebsiteString.read(),\"lxml\")\n",
    "print(soup.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "print (soup.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    WebsiteString = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "    soup = BeautifulSoup(WebsiteString.read(),\"lxml\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(soup.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'attribut'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(soup.gibtsned.attribut)\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website existiert\n",
      "None\n",
      "'gibtsned' gibts ned\n"
     ]
    }
   ],
   "source": [
    "Website = urlopen(\"http://www.wetter.at/\")\n",
    "if Website is None:\n",
    "    print(\"could not open\")\n",
    "else:\n",
    "    print(\"Website existiert\")\n",
    "soup = BeautifulSoup(Website,\"lxml\")\n",
    "print(soup.tagdassnichtgibt)\n",
    "if soup.gibtsned is None:\n",
    "    print(\"'gibtsned' gibts ned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'SubTagdasauchnichtexistiert'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    badContent = soup.tagdassnichtgibt.SubTagdasauchnichtexistiert\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print(\"badContent ist leer\")\n",
    "    else:\n",
    "        print(\"passt alles\")\n",
    "    # tu was mit badContent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zusammenfassend, als erstes Webausleseprogramm mit Sicherheitsvorkehrungen:\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def WSiteTitel(url):\n",
    "    try:\n",
    "        htmlCode = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        soupObject = BeautifulSoup(htmlCode.read())\n",
    "        Titel = soupObject.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return Titel\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file c:\\python3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"content-top-console__title\">\n",
      "        Die Wetter-Storys des Tages\n",
      "    </h1>\n"
     ]
    }
   ],
   "source": [
    "# Ausführung des obigen Programmes:\n",
    "Titel = WSiteTitel(\"https://www.wetter.at\")\n",
    "if Titel == None:\n",
    "    print(\"Kein Titel gefunden\")\n",
    "else:\n",
    "    print(Titel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Das ist nur ein Beispiel, wie man sich tief in den HTML Code einer Seite eingraben kann\n",
    "BSObjekteinerSeite.findAll(\"table\")[4].findAll(\"tr\")[2].find(\"td\").findAll(\"div\")[1].find(\"a\")\n",
    "# An dieser Stelle nicht zur Ausführung gedacht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
